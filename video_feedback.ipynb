{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "from pathlib import Path\n",
    "# from vlmx.agent import Agent, AgentConfig\n",
    "from dotenv import load_dotenv\n",
    "# from vlmx.context_agent import ContextAwareAgent\n",
    "import os\n",
    "import tempfile\n",
    "# from vlmx.tool_use_agent import ToolUseAgent, TOOL_INSTRUCTION\n",
    "# from vlmx.artifact import ArtifactDisplayHandler, artifacts_to_prompt_parts, ArtifactCollector\n",
    "# from typing import Dict, Any, Optional, List, Union\n",
    "import sys\n",
    "from io import StringIO\n",
    "# from vlmx.utils import string_to_file, join_path, extract_code_from_string\n",
    "# from contextlib import contextmanager\n",
    "from io import StringIO\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "# from prompt_construction import HelperAgent, video_feedback\n",
    "from google import genai\n",
    "from prompt_construction import video_feedback_gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "google_api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "client = genai.Client(api_key=google_api_key)\n",
    "#model = 'gemini-2.0-flash'\n",
    "# model = 'gemini-2.5-pro-exp-03-25'\n",
    "model = 'gemini-2.5-flash-preview-04-17'\n",
    "\n",
    "overall_task = \"stack all of the blocks\"\n",
    "path = '[\"pick up the blue block\", \"put the blue block on the green block\"]'\n",
    "my_file_path = '/Users/christopherwatson/Documents/ML/pi0_transitions/stack_blocks/perfect/right_pick_up_the_blue_block_X_put_the_blue_block_on_the_green_block_X_pick_up_the_red_block_X_put_the_red_block_on_the_blue_block_2025_04_08_10_44_21.mp4_external copy.mp4'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-   [SUCCESS] \"pick up the blue block\": The robot successfully moved to the blue block, closed its gripper around it, and lifted it off the table.\n",
      "-   [SUCCESS] \"put the blue block on the green block\": The robot moved the blue block over the green block and lowered it, successfully placing the blue block on top of the green block before releasing it.\n",
      "\n",
      "*Overall assessment*:\n",
      "The robot did not successfully complete the overall task of stacking all of the blocks. Although it successfully stacked the blue block on the green block according to the plan, the red block remained unstacked on the table.\n"
     ]
    }
   ],
   "source": [
    "response_text = video_feedback_gemini(client, model, my_file_path, overall_task=overall_task, path=path, prompt=\"video_feedback_v3_stop_v2.txt\")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "google_api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "client = genai.Client(api_key=google_api_key)\n",
    "my_file_path = '/Users/christopherwatson/Documents/ML/pi0_transitions/stack_blocks/perfect/right_pick_up_the_blue_block_X_put_the_blue_block_on_the_green_block_X_pick_up_the_red_block_X_put_the_red_block_on_the_blue_block_2025_04_08_10_44_21.mp4_external copy.mp4'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "myfile = client.files.upload(file=my_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='files/jmdf1dhzkcn3' display_name=None mime_type='video/mp4' size_bytes=4417614 create_time=datetime.datetime(2025, 4, 28, 18, 7, 30, 480973, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 4, 30, 18, 7, 30, 443418, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 4, 28, 18, 7, 30, 480973, tzinfo=TzInfo(UTC)) sha256_hash='ZDE2YzNkODc3NTQ0YzM0OTI1NzlmNjI3YzcyNjEzNTMzZmY0NjRmZDZjMTQ4MmI5YTdhYjE5YTg1MjVhZDUxNA==' uri='https://generativelanguage.googleapis.com/v1beta/files/jmdf1dhzkcn3' download_uri=None state=<FileState.PROCESSING: 'PROCESSING'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n"
     ]
    }
   ],
   "source": [
    "print(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name_list = ['gpt-4o']\n",
    "#model_name_list = ['gemini-2.5-pro-exp-03-25']\n",
    "model_name_list = ['gemini-2.0-flash']\n",
    "model_dict = {}\n",
    "load_dotenv()\n",
    "for model_name in model_name_list:\n",
    "    cfg = AgentConfig(model_name=model_name,\n",
    "            out_dir=f\"test_results\",)\n",
    "    model_dict[model_name] = HelperAgent(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are asking gemini-2.0-flash\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'google.generativeai.types' has no attribute 'Part'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, agent \u001b[38;5;129;01min\u001b[39;00m model_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe are asking \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mvideo_feedback\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverall_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ML/vlmx/prompt_construction.py:218\u001b[0m, in \u001b[0;36mvideo_feedback\u001b[0;34m(agent, video, overall_task, path, prompt)\u001b[0m\n\u001b[1;32m    214\u001b[0m prompt_parts \u001b[38;5;241m=\u001b[39m construct_prompt(\n\u001b[1;32m    215\u001b[0m     prompt_txt_file, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVIDEO\u001b[39m\u001b[38;5;124m\"\u001b[39m: video, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOVERALL_TASK\u001b[39m\u001b[38;5;124m\"\u001b[39m: overall_task, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;124m\"\u001b[39m: path})\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# This is the hacky part:\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m prompt_parts \u001b[38;5;241m=\u001b[39m \u001b[43mhacky_prompt_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_parts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# I modified HelperAgent to be able to cope with this when everything is a String.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m response \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mgenerate_prediction(prompt_parts)\n",
      "File \u001b[0;32m~/Documents/ML/vlmx/prompt_construction.py:184\u001b[0m, in \u001b[0;36mhacky_prompt_processing\u001b[0;34m(prompt_parts)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhacky_prompt_processing\u001b[39m(prompt_parts):\n\u001b[1;32m    183\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' This gives you the contents field you can put into a generate_content gemini request.'''\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     parts \u001b[38;5;241m=\u001b[39m [hacky_prompt_part_processing(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompt_parts]\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m types\u001b[38;5;241m.\u001b[39mContent(parts)\n",
      "File \u001b[0;32m~/Documents/ML/vlmx/prompt_construction.py:184\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhacky_prompt_processing\u001b[39m(prompt_parts):\n\u001b[1;32m    183\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' This gives you the contents field you can put into a generate_content gemini request.'''\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     parts \u001b[38;5;241m=\u001b[39m [\u001b[43mhacky_prompt_part_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompt_parts]\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m types\u001b[38;5;241m.\u001b[39mContent(parts)\n",
      "File \u001b[0;32m~/Documents/ML/vlmx/prompt_construction.py:179\u001b[0m, in \u001b[0;36mhacky_prompt_part_processing\u001b[0;34m(prompt_part)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m types\u001b[38;5;241m.\u001b[39mPart(inline_data\u001b[38;5;241m=\u001b[39mtypes\u001b[38;5;241m.\u001b[39mBlob(data\u001b[38;5;241m=\u001b[39mvideo_bytes, mime_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo/mp4\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPart\u001b[49m(text\u001b[38;5;241m=\u001b[39mprompt_part)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'google.generativeai.types' has no attribute 'Part'"
     ]
    }
   ],
   "source": [
    "video_dir = '/Users/christopherwatson/Documents/ML/pi0_transitions/stack_blocks/perfect'\n",
    "full_video_path = Path(video_dir) / 'right_pick_up_the_blue_block_X_put_the_blue_block_on_the_green_block_X_pick_up_the_red_block_X_put_the_red_block_on_the_blue_block_2025_04_08_10_44_21.mp4_external.mp4'\n",
    "full_video_path = str(full_video_path)\n",
    "\n",
    "\n",
    "\n",
    "overall_task = \"stack the blocks\"\n",
    "path = '[\"stack the blocks\"]'\n",
    "for model_name, agent in model_dict.items():\n",
    "    print(f\"We are asking {model_name}\")\n",
    "    response = video_feedback(agent, full_video_path, overall_task, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['welcome', 'to', 'eart']\n"
     ]
    }
   ],
   "source": [
    "myl = [\"welcome\", \"to\", \"eart\"]\n",
    "print(myl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlmx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
