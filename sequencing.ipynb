{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from vlmx.agent import Agent, AgentConfig\n",
    "from dotenv import load_dotenv\n",
    "from vlmx.context_agent import ContextAwareAgent\n",
    "import os\n",
    "import tempfile\n",
    "from vlmx.tool_use_agent import ToolUseAgent, TOOL_INSTRUCTION\n",
    "from vlmx.artifact import ArtifactDisplayHandler, artifacts_to_prompt_parts, ArtifactCollector\n",
    "from typing import Dict, Any, Optional, List, Union\n",
    "import sys\n",
    "from io import StringIO\n",
    "from vlmx.utils import string_to_file, join_path, extract_code_from_string\n",
    "from contextlib import contextmanager\n",
    "from io import StringIO\n",
    "from PIL import Image\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(prompt_txt_path, content_dict, special_separator=\"<|>\"):\n",
    "    with open(prompt_txt_path, 'r') as f:\n",
    "        prompt = f.read()\n",
    "    for key, value in content_dict.items():\n",
    "        if isinstance(value, str):\n",
    "            # assert not os.path.exists(value), f\"Expected a string value for {key}, but got a file path: {value}\"\n",
    "            prompt = prompt.replace(f\"{special_separator}{key}{special_separator}\", value)\n",
    "    prompt_parts = []\n",
    "    current_pos = 0\n",
    "    while True:\n",
    "        # Find next separator\n",
    "        next_sep = prompt.find(special_separator, current_pos)\n",
    "        if next_sep == -1:\n",
    "            # Add remaining text\n",
    "            if current_pos < len(prompt):\n",
    "                prompt_parts.append(prompt[current_pos:])\n",
    "            break\n",
    "            \n",
    "        # Add text before separator\n",
    "        if current_pos < next_sep:\n",
    "            prompt_parts.append(prompt[current_pos:next_sep])\n",
    "            \n",
    "        # Find end of key\n",
    "        end_sep = prompt.find(special_separator, next_sep + len(special_separator))\n",
    "        if end_sep == -1:\n",
    "            raise ValueError(f\"Unmatched separator at position {next_sep}\")\n",
    "            \n",
    "        # Extract key and get corresponding image\n",
    "        key = prompt[next_sep + len(special_separator):end_sep]\n",
    "        if key in content_dict:\n",
    "            prompt_parts.append(content_dict[key])\n",
    "        else:\n",
    "            raise ValueError(f\"Key {key} not found in content_dict\")\n",
    "            \n",
    "        current_pos = end_sep + len(special_separator)\n",
    "    return prompt_parts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are providing guidance to a robot as it completes a manipulation task.\n",
      "In particular, you need to tell the robot when it has successfully completed the current skill (subtask) so it knows when it can move on to the next step.\n",
      "We will show you an image that shows the current scene, and we will ask you if a particular skill (subtask) has been successfully completed.\n",
      "You must answer with either 'True' or 'False'.\n",
      "Ok here is the image of the current state:\n",
      "\n",
      "<PIL.Image.Image image mode=RGB size=100x100 at 0x11A51EDD0>\n",
      "\n",
      "Has the robot successfully completed the skill: \"pick up the blue block\" (answer 'True' or 'False')\n"
     ]
    }
   ],
   "source": [
    "text_only_dict = {'SKILL': 'pick up the blue block', 'CURRENT_IMAGE': red_image}\n",
    "prompt_parts = construct_prompt('./prompts/skill_completion.txt', text_only_dict)\n",
    "for part in prompt_parts:\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_INSTRUCTION = \"Please follow the instructions in the prompt.\"\n",
    "class HelperAgent(Agent):\n",
    "    OUT_RESULT_PATH = \"test.txt\"\n",
    "\n",
    "    def _make_system_instruction(self):\n",
    "        return SYSTEM_INSTRUCTION\n",
    "\n",
    "    def _make_prompt_parts(self, question: str):\n",
    "        return question\n",
    "\n",
    "    def parse_response(self, response):\n",
    "        print(\"response:\", response.text)\n",
    "        ## string_to_file(response.txt, \"path.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying gpt-4o... on PRE\n",
      "response: False\n",
      "False\n",
      "Trying gpt-4o... on ALMOST\n",
      "response: False\n",
      "False\n",
      "Trying gpt-4o... on GRASP\n",
      "response: False\n",
      "False\n",
      "Trying gpt-4o... on LIFTING\n",
      "response: False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Let's test skill skill_completion.txt for the grasp_blue_block task\n",
    "video_dir = '/Users/christopherwatson/Documents/ML/pi0_transitions/stack_blocks/perfect'\n",
    "images_dict = {\n",
    "    'PRE': Path(video_dir) / 'pick_up_the_blue_block_PRE.jpg',\n",
    "    'ALMOST': Path(video_dir) / 'pick_up_the_blue_block_ALMOST.jpg',\n",
    "    'GRASP': Path(video_dir) / 'pick_up_the_blue_block_GRASP.jpg',\n",
    "    'LIFTING': Path(video_dir) / 'pick_up_the_blue_block_LIFTING.jpg',\n",
    "}\n",
    "for k in images_dict:\n",
    "    images_dict[k] = Image.open(images_dict[k])\n",
    "model_name_list = ['gpt-4o']\n",
    "model_dict = {}\n",
    "load_dotenv()\n",
    "for model_name in model_name_list:\n",
    "    cfg = AgentConfig(model_name=model_name,\n",
    "            out_dir=f\"test_results\",)\n",
    "    model_dict[model_name] = HelperAgent(cfg)\n",
    "\n",
    "for image_name, image in images_dict.items():\n",
    "    for model_name, model in model_dict.items():\n",
    "        print(f\"Trying {model_name}... on {image_name}\")\n",
    "        messages = construct_prompt('./prompts/skill_completion_predicate.txt', {'SKILL': 'pick up the blue block', 'PRE_IMAGE': images_dict['PRE'], 'CURRENT_IMAGE': image, 'PREDICATE': 'GRASPING BLUE BLOCK'})\n",
    "        response = model.generate_prediction(messages, gen_config={'temperature': 0.0})\n",
    "        print(response.text)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlmx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
